{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78bb933f",
   "metadata": {},
   "source": [
    "# TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428f142",
   "metadata": {},
   "source": [
    "Transfer Learning \n",
    "Transfer Learning bir şeyi bir yerden bir yere taşımak. Öğrenilen bir şeyi taşımak gibi düşünülebilir. Deep learning’de transfer learning kavramı nedir? \n",
    "\n",
    "Bir CNN yapısı düşünelim. Bu CNN yapısında bir input var ve bu input layer’lardan geçiyor. Ardından bir output üretilir. Peki, bu CNN yapısını eğittiğimiz zaman neleri öğreniyoruz. 1. Filtreler 2. Weight değerlerini(Fully Connected değerleri) öğrenmiş oluyoruz. Öncesinde binlerce class’ı olan bir dataset eğitip ardından öğrendiğimiz bu weight değerlerini elimizde tutup ardından başka class’lara sahip olan bir veriseti için kullanabilmek özelliği “Transfer Learning” denir. “Low Level Seviyede” öğrenilmiş weightler ile farklı bir datasetini eğitmeyi mümkün kılmaktır. Bu olaya “PreTrained” denir. Yeni class için “fine funing” denir. \n",
    "Farklı bir şekilde elde almak istersek bir verisetinin kedi ve köpek class’larını sınıflandrmak için kullandığımızı ve eğittiğimizi düşünürsek; ve output değerlerini elde ettiğimizi varsayarsak, ekstra bir class daha(mesela hamster) classify etmek istersek binary classification(sigmoid function) adımına kadar olan kısmını kullanarak farklı bir hayvanı classify etmek için farklı bir “aktivasyon fonksiyonu” kullanarak aynı weight değerleri ile eğitilebilir. Yani eğitim adımında işimize yarayacak kısmını kullanmaktır. \n",
    "\n",
    "Transfer Learning Avantajları: Zaman- HyperParametre Tuning- (Resimlerin low level ve neredeyse middle level feature’ları aynıdır.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22371465",
   "metadata": {},
   "source": [
    "Transfer Learning Örnekleri :  VGG(keras ile ImageNet sınıfı) ve ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c9cd16",
   "metadata": {},
   "source": [
    "Transfer Learning\n",
    "Biz Transfer Learning kavramını anlayabilmek için Fruit360 datasetini kullanacağız. \n",
    "Öncesinde gerekli kütüphanelerimizi import etmekle işe başlayacağız. Ardından Fruit360 datasetimizin içinde train ve test verisetimizin yoluunu gösterelim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7a97a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.applications.vgg16 import VGG16  #VGG16 modeli import edilmiştir.\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e84d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path= \"C:/Desktop/fruits-360_dataset/fruits-360/Training\"\n",
    "test_path= \"C:/Desktop/fruits-360_dataset/fruits-360/Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65c56a8",
   "metadata": {},
   "source": [
    "Şimdi ise glob fonksiyonu yardımıyla sınıf sayımızı öğrenelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2bb66af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfClass = len(glob(train_path+\"/*\"))\n",
    "numberOfClass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5dc2d",
   "metadata": {},
   "source": [
    "#  VGG16 MODELİ KULLANIMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa98cf",
   "metadata": {},
   "source": [
    "Önce vgg modelinden bir obje yaratalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a89e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16 \n",
    "vgg = VGG16(include_top = False,input_shape = (100,100,3)) #16 layerdan oluşan VGG modeli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c389cf8d",
   "metadata": {},
   "source": [
    "Şimdi VGG16 modelinin özetine bakalım ve bizim datasetimize uyarlamak adımına geçelim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0180532c",
   "metadata": {},
   "source": [
    "İçinde varolan tüm layer’ları ve train edilecebilecek görsel sayıları, total parametreleri gibi özellikleri gördük. Şimdi ise incelediğimizde VGG16 modelinin 1000 sınıfı sınıflandırabilme yetkisinin olduğunu gördük fakat bizim class sayımızı sadece 96 adettir. Haliyle “Prediction” layer’ını modelden silip bizim için uygun olabilecek bir Dense Layer ekleyebiliriz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f1299d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(vgg.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8116f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.functional.Functional'>\n"
     ]
    }
   ],
   "source": [
    "print(type(vgg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a3d0f",
   "metadata": {},
   "source": [
    "Öncesinde tüm layer’ları bir liste içine atalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a07be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.input_layer.InputLayer object at 0x0000016FCEF3D4B0>, <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016FDBBA4F10>, <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016FDBBA5180>, <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000016FDBBA61D0>, <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016FDBBA5930>, <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016FDCF93C70>, <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000016FDCFB7F40>, <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016FDCFB67A0>, <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016FDCFD3910>, <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016FDCFD3AF0>, <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000016FDCFF3610>, <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016FDCFF2980>, <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016FDCFF0F40>, <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016FDCFD2E60>, <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000016FDBBA6BF0>, <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016FDCFD05B0>, <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016FDCF919C0>, <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016FDCF91C00>, <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000016FDD0277F0>]\n"
     ]
    }
   ],
   "source": [
    "vgg_layer_list = vgg.layers\n",
    "print(vgg_layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6209baf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vgg_layer_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d545a0a",
   "metadata": {},
   "source": [
    "Bir layer ekleyeceğimizi belirtmiştik. Şimdi ise layer’ı ekleyelim. Bu adım Sequential() bir şekilde gerçekleşeceğinden ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e44be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c388abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(vgg_layer_list)-1):\n",
    "    model.add(vgg_layer_list[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b14489f",
   "metadata": {},
   "source": [
    "Yalnızca son satırı ekleyip kullanacağımız için diğer layer’ların trainable özelliğini kapatıyoruz. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb676a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layers in model.layers:\n",
    "    layers.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4635aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(256, activation=\"relu\")) \n",
    "model.add(Dense(150, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6398ed",
   "metadata": {},
   "source": [
    "Yukarıdaki kod ile model'e Dense layer yani output layer ekledik. Output layer'ında belirtmemiz gereken 2 tane özellik var. Birincisi number of class'tır yani kaç tane nörondan oluşacağıdır. Yukarıdaki satırlarda tanımladığımız numberOfClass değişkeninde 131 değeri bulunmaktadır. Aktivasyon fonksiyonu da multiclass için kullandığımız Softmax fonksiyonu olacaktır.\n",
    "\n",
    "Şimdi modelin katmanlarına bakalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16cb0dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(numberOfClass, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6192584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               4718848   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               38550     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 131)               19781     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,491,867\n",
      "Trainable params: 4,777,179\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f238a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"rmsprop\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b01698",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443ef99",
   "metadata": {},
   "source": [
    "Şimdi train işlemine geçebiliriz.\n",
    "Öncelikle vgg modelimizin input_shape= 224,224 olduğu için ImageGenerator kullanarak verilen directory de olan yani test ve train verisetlerini 224,224 haline getiriyoruz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b088a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67692 images belonging to 131 classes.\n",
      "Found 22688 images belonging to 131 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derin\\AppData\\Local\\Temp\\ipykernel_3076\\2448932319.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model.fit_generator(train_data,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "50/50 [==============================] - 63s 1s/step - loss: 12.6166 - accuracy: 0.1531 - val_loss: 3.9664 - val_accuracy: 0.2138\n",
      "Epoch 2/13\n",
      "50/50 [==============================] - 78s 2s/step - loss: 3.8819 - accuracy: 0.2463 - val_loss: 3.9982 - val_accuracy: 0.2650\n",
      "Epoch 3/13\n",
      "50/50 [==============================] - 77s 2s/step - loss: 3.4086 - accuracy: 0.3381 - val_loss: 4.2431 - val_accuracy: 0.2800\n",
      "Epoch 4/13\n",
      "50/50 [==============================] - 74s 1s/step - loss: 2.9974 - accuracy: 0.4100 - val_loss: 3.6780 - val_accuracy: 0.3812\n",
      "Epoch 5/13\n",
      "50/50 [==============================] - 74s 1s/step - loss: 2.4199 - accuracy: 0.5144 - val_loss: 3.0134 - val_accuracy: 0.4137\n",
      "Epoch 6/13\n",
      "50/50 [==============================] - 75s 2s/step - loss: 2.1416 - accuracy: 0.5650 - val_loss: 2.7077 - val_accuracy: 0.4750\n",
      "Epoch 7/13\n",
      "50/50 [==============================] - 75s 2s/step - loss: 1.9087 - accuracy: 0.6044 - val_loss: 2.1486 - val_accuracy: 0.5337\n",
      "Epoch 8/13\n",
      "50/50 [==============================] - 76s 2s/step - loss: 1.6758 - accuracy: 0.6544 - val_loss: 2.2116 - val_accuracy: 0.5925\n",
      "Epoch 9/13\n",
      "50/50 [==============================] - 76s 2s/step - loss: 1.4856 - accuracy: 0.7050 - val_loss: 2.3710 - val_accuracy: 0.6388\n",
      "Epoch 10/13\n",
      "50/50 [==============================] - 75s 2s/step - loss: 1.1871 - accuracy: 0.7394 - val_loss: 2.1286 - val_accuracy: 0.6500\n",
      "Epoch 11/13\n",
      "50/50 [==============================] - 78s 2s/step - loss: 1.0957 - accuracy: 0.7775 - val_loss: 1.9267 - val_accuracy: 0.6712\n",
      "Epoch 12/13\n",
      "50/50 [==============================] - 85s 2s/step - loss: 1.1761 - accuracy: 0.7806 - val_loss: 3.0161 - val_accuracy: 0.6700\n",
      "Epoch 13/13\n",
      "50/50 [==============================] - 83s 2s/step - loss: 1.0036 - accuracy: 0.8144 - val_loss: 2.6814 - val_accuracy: 0.6600\n"
     ]
    }
   ],
   "source": [
    "# train  \n",
    "train_data = ImageDataGenerator().flow_from_directory(train_path,target_size = (100,100))\n",
    "test_data = ImageDataGenerator().flow_from_directory(test_path,target_size = (100,100))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "hist = model.fit_generator(train_data,\n",
    "                           steps_per_epoch=1600//batch_size,\n",
    "                           epochs= 13,\n",
    "                           validation_data=test_data,\n",
    "                           validation_steps= 800//batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "601f728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"deneme.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a080262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "#loss\n",
    "print(hist.history.keys())\n",
    "plt.plot(hist.history[\"loss\"],label=\"training loss\")\n",
    "plt.plot(hist.history[\"val_loss\"],label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e797b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "#accuracy\n",
    "print(hist.history.keys())\n",
    "plt.plot(hist.history[\"accuracy\"],label=\"training accuracy\")\n",
    "plt.plot(hist.history[\"val_accuracy\"],label=\"validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a5f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save history\n",
    "import json, codecs\n",
    "with open(\"deneme.json\",\"w\") as f:\n",
    "    json.dump(hist.history,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4460e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load history\n",
    "with codecs.open(\"deneme.json\",\"r\",encoding=\"utf-8\") as f:\n",
    "    n = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d564bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c55e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "#loss\n",
    "plt.plot(n[\"loss\"],label=\"training loss\")\n",
    "plt.plot(n[\"val_loss\"],label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5367705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "#accuracy\n",
    "plt.plot(n[\"accuracy\"],label=\"training accuracy\")\n",
    "plt.plot(n[\"val_accuracy\"],label=\"validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567722b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
